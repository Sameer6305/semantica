{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# End-to-End Advanced GraphRAG with Semantica\n",
                "\n",
                "## Overview\n",
                "\n",
                "This notebook provides a comprehensive, \"production-grade\" walkthrough of the **Semantica** framework. We will build a complete **GraphRAG** (Graph-Restricted Retrieval Augmented Generation) pipeline using diverse real-world data sources.\n",
                "\n",
                "### üîë Key Modules Used\n",
                "\n",
                "*   **`semantica.ingest`**: Ingestion from Web, RSS, and Git.\n",
                "*   **`semantica.normalize`**: Cleaning and standardizing raw text.\n",
                "*   **`semantica.split`**: Semantic document chunking.\n",
                "*   **`semantica.kg`**: KG construction and graph analytics.\n",
                "*   **`semantica.vector_store`**: Vector similarity search.\n",
                "*   **`semantica.reasoning`**: Advanced graph-based inference.\n",
                "*   **`semantica.visualization`**: Interactive and static KG viz.\n",
                "*   **`semantica.export`**: Data persistence and sharing.\n",
                "\n",
                "### üéØ Objective\n",
                "\n",
                "Build a queryable knowledge base about **Python Development & AI News** by aggregating data from:\n",
                "1.  **Web**: Python.org\n",
                "2.  **RSS**: BBC Technology News\n",
                "3.  **Repo**: The requests library"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Installation & Setup\n",
                "!pip install -qU semantica networkx matplotlib plotly pandas faiss-cpu tiktoken"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Core Configuration\n",
                "\n",
                "We start by initializing the global `Semantica` configuration."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from semantica.core import Semantica, ConfigManager\n",
                "\n",
                "config = {\n",
                "    \"project_name\": \"PythonAI_FullPipeline\",\n",
                "    \"embedding\": {\"provider\": \"openai\", \"model\": \"text-embedding-3-small\"},\n",
                "    \"extraction\": {\"model\": \"gpt-4o-mini\", \"temperature\": 0.0},\n",
                "    \"vector_store\": {\"provider\": \"faiss\", \"dimension\": 1536}\n",
                "}\n",
                "\n",
                "sem = Semantica(config=ConfigManager().load_from_dict(config))\n",
                "print(\"‚úÖ Semantica Core Initialized.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Ingestion & Normalization\n",
                "\n",
                "Fetching real-world data and cleaning it immediately using the `normalize` module."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from semantica.ingest import WebIngestor, FeedIngestor, ingest\n",
                "from semantica.normalize import TextNormalizer\n",
                "\n",
                "normalizer = TextNormalizer()\n",
                "\n",
                "# üåê Fetch Data\n",
                "web_docs = WebIngestor().ingest(\"https://www.python.org/about/\", method=\"url\")\n",
                "feed_docs = FeedIngestor().ingest(\"http://feeds.bbci.co.uk/news/technology/rss.xml\")[:3] # Sample 3\n",
                "repo_docs = ingest(\"https://raw.githubusercontent.com/psf/requests/main/README.md\", source_type=\"web\")\n",
                "\n",
                "# üßπ Clean Data\n",
                "raw_texts = [d.content if hasattr(d, 'content') else str(d) for d in web_docs + feed_docs + repo_docs]\n",
                "clean_texts = [normalizer.normalize(t) for t in raw_texts if t]\n",
                "\n",
                "print(f\"‚úÖ Ingested and Normalized {len(clean_texts)} documents.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Semantic Splitting\n",
                "\n",
                "Breaking large documents into contextually aware chunks."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from semantica.split import TextSplitter\n",
                "\n",
                "splitter = TextSplitter(method=\"recursive\", chunk_size=800, chunk_overlap=150)\n",
                "chunks = []\n",
                "for text in clean_texts:\n",
                "    chunks.extend(splitter.split(text))\n",
                "\n",
                "print(f\"‚úÖ Generated {len(chunks)} Chunks.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Knowledge Graph & Storage\n",
                "\n",
                "Building the structural (Graph) and semantic (Vector) layers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from semantica.kg import GraphBuilder\n",
                "from semantica.vector_store import VectorStore\n",
                "\n",
                "# üèóÔ∏è Graph\n",
                "gb = GraphBuilder(merge_entities=True)\n",
                "kg = gb.build(sources=[{\"text\": str(c)} for c in chunks[:5]]) # Limited for demo\n",
                "\n",
                "# üíæ Vectors\n",
                "vs = VectorStore(backend=\"faiss\", dimension=1536)\n",
                "embeddings = sem.embedding_generator.generate_embeddings([str(c) for c in chunks[:5]])\n",
                "vs.store_vectors(vectors=embeddings, metadata=[{\"text\": str(c)} for c in chunks[:5]])\n",
                "\n",
                "print(f\"‚úÖ KG Built ({kg.number_of_nodes()} nodes). Vector Store Populated.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Graph Analytics & Viz\n",
                "\n",
                "Understanding the data through graph theory."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from semantica.kg import CentralityCalculator\n",
                "from semantica.visualization import KGVisualizer\n",
                "\n",
                "centrality = CentralityCalculator().calculate_degree_centrality(kg)\n",
                "print(f\"üèÜ Top Node: {max(centrality, key=centrality.get)}\")\n",
                "\n",
                "KGVisualizer().visualize_network(kg, layout=\"spring\", output=\"static\")\n",
                "import matplotlib.pyplot as plt\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Advanced Reasoning\n",
                "\n",
                "Using the `reasoning` module to perform complex multi-hop inference over the graph."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from semantica.reasoning import GraphReasoner\n",
                "\n",
                "reasoner = GraphReasoner(graph=kg)\n",
                "query = \"How does Python relate to the latest tech trends?\"\n",
                "\n",
                "# Perform multi-hop reasoning over the KG\n",
                "reasoning_result = reasoner.reason(query, depth=2)\n",
                "print(f\"üß† Reasoning Results:\\n{reasoning_result[:300]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Context & Export\n",
                "\n",
                "Wrapping context for an agent and exporting the final Knowledge Graph."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from semantica.context import AgentContext\n",
                "from semantica.export import GraphExporter\n",
                "\n",
                "# ü§ñ Context\n",
                "context = AgentContext(vector_store=vs, knowledge_graph=kg)\n",
                "\n",
                "# üì§ Export\n",
                "exporter = GraphExporter()\n",
                "exporter.export_to_json(kg, \"python_tech_graph.json\")\n",
                "\n",
                "print(\"‚úÖ Context Ready. Knowledge Graph Exported to JSON.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}